{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb91df1-77f1-4467-b043-d0b6cc7377e4",
   "metadata": {},
   "source": [
    "# Particle Identification using GNN on HGCAL dataset- Adding PILEUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2d038-e2c3-46ab-88bd-93d4527e39ec",
   "metadata": {},
   "source": [
    "We have already done the following:\n",
    "1. Added a Gaussian Noise.\n",
    "2. We had done the normalization per hit per layer. This had completely removed the longitudinal profile information. We only had the lateral profile- per layer relative energy at each hit cell, with respect to the hit cell with maximum energy deposit in that particular layer\n",
    "3. We added the longitudinal profile information manually using the *layer profile*, which is the normalized tensor, representing the per event relative total energy in each layer, with respect to the layer with maximum total hit energy.\n",
    "4. We had developed a more **intense** architecture.\n",
    "5. We had further added a **Graph Attention Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faae6f2-427c-4c30-a1a2-9e62cdbb9e1e",
   "metadata": {},
   "source": [
    "Now, we shall do a further important topic,i.e, adding **pileup events**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71560501-5bd5-4d1d-a323-65a0c99869ec",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737133ca-4c6e-41c7-81e6-ab9aca2cd3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General packages\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Packages for GNN\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "#from torch_geometric.nn import GCNConv, global_add_pool\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec0310-8720-4d28-bdab-0adaa448d323",
   "metadata": {},
   "source": [
    "## ROOT ---> Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58912548-98a3-417f-bedc-dbff20f1fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file=uproot.open(\"ntuple_pi+_100GeV_100keve.root:AllLayers\")\n",
    "#branches=[\"hit_x\",\"hit_y\",\"hit_z\",\"hit_l\",\"hit_E\"]\n",
    "#events=file.arrays(branches,library=\"ak\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89261988-9c1e-4370-8eb8-ef5a7cbfef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events  ### Awkawrd array in Dictionary like format\n",
    "#type(events)\n",
    "#events.hit_x # Returns the awkard arrays for the hit_x for all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801917d-21c9-4174-8d65-47c2ff60ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events[0].hit_x # Returns the hit_x data for the first event, as numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50a8158-457c-4ac1-b076-f95ed99e8910",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576e8a6-9699-4028-a97f-0a507590e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the root files and their path names\n",
    "particle_files={\n",
    "    \"pi+\":\"ntuple_pi+_100GeV_100keve.root:AllLayers\",\n",
    "    \"e+\":\"ntuple_e+_100_GeV_100Keve.root:AllLayers\",\n",
    "    \"Y\":\"ntuple_gamma_100GeV_25keve_p1.root:AllLayers\",\n",
    "    \"K-\":\"ntuple_kaon-_100GeV_20keve_p1.root:AllLayers\",\n",
    "    \"K+\":\"ntuple_kaon+_100GeV_20keve_p1.root:AllLayers\",\n",
    "    \"K_0\":\"ntuple_kaon0L_100GeV_10keve_test.root:AllLayers\",\n",
    "    \"mu+\":\"ntuple_mu+_100GeV_100keve.root:AllLayers\",\n",
    "    \"n\":\"ntuple_neutron_100GeV_10keve_test.root:AllLayers\",\n",
    "    \"p\":\"ntuple_proton_100GeV_20keve_p1.root:AllLayers\"\n",
    "}\n",
    "particle_ids={\n",
    "    \"pi+\":0,\n",
    "    \"e+\":1,\n",
    "    \"Y\":2,\n",
    "    \"K-\":3,\n",
    "    \"K+\":4,\n",
    "    \"K_0\":5,\n",
    "    \"mu+\":6,\n",
    "    \"n\":7,\n",
    "    \"p\":8\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23b2e3-1e6f-4884-968c-f42a331ef690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the root files and their path names\n",
    "particle_files={\n",
    "    \"pi+\":\"ntuple_pi+_100GeV_100keve.root:AllLayers\",\n",
    "    \"e+\":\"ntuple_e+_100_GeV_100Keve.root:AllLayers\",\n",
    "    \"Y\":\"ntuple_gamma_100GeV_25keve_p1.root:AllLayers\",\n",
    "    \n",
    "}\n",
    "particle_ids={\n",
    "    \"pi+\":0,\n",
    "    \"e+\":1,\n",
    "    \"Y\":2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a79b4d-7ae4-4c83-8fbc-cc204ddde3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "branches=[\"hit_x\",\"hit_y\",\"hit_z\",\"hit_l\",\"hit_E\"]\n",
    "all_events=[]\n",
    "all_labels=[]\n",
    "\n",
    "for pname,file_path in particle_files.items():\n",
    "    file=uproot.open(file_path)\n",
    "    events=file.arrays(branches,library=\"ak\")[:1000] #Only 1000 events for now\n",
    "    #Assigning particle ids\n",
    "    pid=particle_ids[pname]\n",
    "    #Store everything as a tuple\n",
    "    all_events.extend([(events[i],pid) for i in range(len(events))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c7c35-7686-482d-9460-b744c866d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling\n",
    "from sklearn.utils import shuffle\n",
    "all_events=shuffle(all_events,random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991e7d3-52a6-4a75-9551-26186d7b8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94efe607-bd09-44a3-b669-e968b0105db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e6f71-212f-4094-bd9d-7cfd962cfd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pid = {v: k for k, v in particle_ids.items()}\n",
    "#class_names=[pid[i] for i in range(len(pid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ab7ec-b36f-40c5-a011-5f3a1b047244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e92c649-104b-4f16-b8b8-d25e063d23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,name in enumerate(class_names):\n",
    "#    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbd1da-7d4a-487d-86a0-a372d37c302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events[4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b198094-72bc-4085-91e1-5418621cfdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(all_events[0][0].hit_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60501e-5a72-4587-999c-93cdf654db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(all_events[0][0].hit_E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb85bdd-a982-42d7-ac47-08b3da4cbd93",
   "metadata": {},
   "source": [
    "## Adding Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45714cc-197b-4c11-9662-eb1cb4fdefd3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd95384-b1f3-4a61-9b66-1acc658a009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_HGCAL_noise(event,noise_mean,N=0.05,threshold_sigma=None,random_state=None):\n",
    "    signal=np.array(event.hit_E)\n",
    "    #Computing the sigma\n",
    "    #sigma=np.sqrt((a**2)*signal + b**2)\n",
    "    sigma=N\n",
    "    #Compute the Gaussian noise, with this sigma\n",
    "    noise=np.random.normal(loc=0.0,scale=sigma,size=np.size(signal))\n",
    "    E_noisy=signal+noise\n",
    "    #Clipping zero and negative energies\n",
    "    E_noisy[E_noisy<=0]=0.0\n",
    "    #Optional zero suppression- based on threshold\n",
    "    if threshold_sigma is not None:\n",
    "        threshold=threshold_sigma*b\n",
    "        E_noisy[E_noisy<threshold]=0.0\n",
    "    #Newly record the data\n",
    "    event_noisy=ak.Record(\n",
    "    {\n",
    "        \"hit_x\":event.hit_x,\n",
    "        \"hit_y\":event.hit_y,\n",
    "        \"hit_z\":event.hit_z,\n",
    "        \"hit_l\":event.hit_l,\n",
    "        \"hit_E\":E_noisy\n",
    "    })\n",
    "    \n",
    "    return event_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b6aee-18ae-4940-97bf-5415f990d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) #For explaining reproductivity\n",
    "all_events_noisy=[]\n",
    "noise_mean=0.0\n",
    "#noise_std=0.03\n",
    "\n",
    "for event,pid in all_events:\n",
    "    event_noisy=add_HGCAL_noise(event,noise_mean=noise_mean)\n",
    "    all_events_noisy.append((event_noisy,pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c6379-35f7-408e-80ff-18b591c9c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_noisy[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e36e7-1881-428d-82ad-5ec1e46c9775",
   "metadata": {},
   "source": [
    "## Adding PileUp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ce06f-4eda-4e3e-bca7-1eafd29dd27f",
   "metadata": {},
   "source": [
    "We will follow three steps now to create a toy model.\n",
    "1. Generate random numbers following exponential distribution.\n",
    "2. Fit the random numbers in a histogram. This will give me the energy profile for the pileups\n",
    "3. Using this historam, further generate random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c482df3-f738-4004-8a62-56f328620873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7b416f2fa0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from scipy.stats import gaussian_kde\n",
    "#------ Step-1: Generating Random exponential numbers ------#\n",
    "lambda_val=2.0 \n",
    "N_samples=100000\n",
    "exp_vals=np.random.exponential(scale=lambda_val,size=N_samples)\n",
    "#------ Step-2: Build the Histogram ------#\n",
    "num_bins=100\n",
    "counts,bin_edges=np.histogram(exp_vals,bins=num_bins,density=False)\n",
    "#------ Step-3: Sampling from the Histogram -----#\n",
    "#### Build the CDF\n",
    "probablities=counts/np.sum(counts)\n",
    "cdf=np.cumsum(probablities)\n",
    "def sample_from_histogram(n_samples):\n",
    "    sampled_values=[]\n",
    "    for _ in range(n_samples):\n",
    "        u=np.random.rand()\n",
    "        bin_index=np.searchsorted(cdf,u)\n",
    "        #Identify the bin edges\n",
    "        E_low=bin_edges[bin_index]\n",
    "        E_high=bin_edges[bin_index+1]\n",
    "        #Sampling within the bin\n",
    "        r=np.random.rand()\n",
    "        E_sample=E_low+(E_high-E_low)*r\n",
    "        sampled_values.append(E_sample)\n",
    "    return sampled_values\n",
    "sam_vals=sample_from_histogram(100000)\n",
    "#sam_vals=np.array(sam_vals)\n",
    "#x=np.linspace(sam_vals.min(),sam_vals.max(),1000)\n",
    "##### Plotting##### \n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist(exp_vals,bins=100,histtype='step',color='blue',density=True,alpha=0.5,label='Original_Data')\n",
    "plt.hist(sam_vals,bins=100,histtype='step',color='red',linestyle='--',density=True,alpha=0.5,label='Sampled_Data')\n",
    "#sns.kdeplot(data=sam_vals, fill=True, color='purple', label='Estimated PDF (KDE)')\n",
    "#kde=gaussian_kde(sam_vals)\n",
    "#pdf=kde(x)\n",
    "#plt.plot(x, pdf, color='purple', lw=2, label='Estimated PDF (KDE)')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97854d10-c868-44ab-b8b9-38292ef30c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to generate the pileup energy per event.\n",
    "N_pileups_per_event=50\n",
    "\n",
    "def generate_event_pileup(n_pileups,histogram_sample):\n",
    "    # Randomly select 'n_pileups' no. of energies from the histogram\n",
    "    pileup_energy=np.random.choice(histogram_sample,size=n_pileups)\n",
    "    #Total pileup energy per event\n",
    "    total_pileup_energy=np.sum(pileup_energy)\n",
    "    return total_pileup_energy\n",
    "total_E=generate_event_pileup(N_pileups_per_event,sam_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583b8c95-bf0f-4fdc-8aac-11bde2baba2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.15096330636479"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2cd7a8-cc8b-491e-b0cc-80f8c5218a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeb53a2f-f0d9-4378-81d3-f6359eea840f",
   "metadata": {},
   "source": [
    "## Longitudinal profile- Layer Energy Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76ca1c-1306-4e90-a56b-dcd794bc5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_profile(event,global_max_layers=50):\n",
    "    layers=ak.to_numpy(event.hit_l)\n",
    "    layers=torch.tensor(layers)\n",
    "    energies=ak.to_numpy(event.hit_E)\n",
    "    energies=torch.tensor(energies)\n",
    "    layer_sums=torch.bincount(input=layers-1,weights=energies,minlength=global_max_layers)\n",
    "    #Maximum energy\n",
    "    max_energy=layer_sums.max()\n",
    "    if max_energy>0:\n",
    "        layer_sums_norm=layer_sums/max_energy\n",
    "    #return torch.tensor(layer_sums_norm,dtype=torch.float64)\n",
    "    layer_sums_norm=torch.unsqueeze(layer_sums_norm,0)\n",
    "    return layer_sums_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ef119-8a4c-48d1-a01f-a1fdc99fa0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "layer_profile(all_events_noisy[4][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20387f5-c4f2-4d14-ad5e-f96619668f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_profile(all_events_noisy[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18451d26-d8c8-4d7d-b67f-9a19187288e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A=torch.tensor([1,2,3])\n",
    "#B=torch.unsqueeze(A,0)\n",
    "#B.shape\n",
    "#A.unsqueeze(0)\n",
    "#print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332cb82-3015-4c3c-b6c8-2689607968cd",
   "metadata": {},
   "source": [
    "## Lateral Profile- Average energy per hits per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffcd35-0340-412b-8f64-2064c6889d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_hits_by_layer(event):\n",
    "    layer=ak.to_numpy(event.hit_l)\n",
    "    energy=ak.to_numpy(event.hit_E)\n",
    "    #Prepare an array to store normalized energies\n",
    "    energy_norm=np.zeros_like(energy)\n",
    "    #Finding unique layers\n",
    "    unique_layer=np.unique(layer)\n",
    "    for l in unique_layer:\n",
    "        #Extract the inndices of the hits in this layer\n",
    "        mask=layer==l\n",
    "        if np.any(mask):\n",
    "            max_energy=energy[mask].max()\n",
    "            if max_energy>0:\n",
    "                energy_norm[mask]=energy[mask]/max_energy\n",
    "            elif max_energy==0:\n",
    "                energy_norm[mask]=0.0\n",
    "    #Rebuild the record\n",
    "    event_norm=ak.Record({\n",
    "        \"hit_x\":event.hit_x,\n",
    "        \"hit_y\":event.hit_y,\n",
    "        \"hit_z\":event.hit_z,\n",
    "        \"hit_l\":event.hit_l,\n",
    "        \"hit_E\":energy_norm\n",
    "    })\n",
    "    return event_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc30869-31b1-400d-abc3-58fa7a482de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_normalized=[]\n",
    "for event,pid in all_events_noisy:\n",
    "    event_norm=normalize_hits_by_layer(event)\n",
    "    all_events_normalized.append((event_norm,pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e12a56-649b-415c-aba8-e38a372b4c8d",
   "metadata": {},
   "source": [
    "## Creating the event graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b5133-5827-4188-b005-8f614cc8485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(event,k=8):\n",
    "    x=ak.to_numpy(event.hit_x)\n",
    "    y=ak.to_numpy(event.hit_y)\n",
    "    z=ak.to_numpy(event.hit_z)\n",
    "    l=ak.to_numpy(event.hit_l)\n",
    "    E=ak.to_numpy(event.hit_E)\n",
    "    #Removing zero energy hits\n",
    "    mask_E=E>0\n",
    "    x,y,z,l,E=x[mask_E],y[mask_E],z[mask_E],l[mask_E],E[mask_E]\n",
    "    coords=np.column_stack((x,y,z))\n",
    "    N=len(coords)\n",
    "    if N<k+1:\n",
    "        return None\n",
    "    \n",
    "    #Node features\n",
    "    node_features=torch.from_numpy(np.column_stack((x,y,z,l,E))).float()\n",
    "\n",
    "    #Global KNN\n",
    "    knn=NearestNeighbors(n_neighbors=k+1,algorithm=\"kd_tree\").fit(coords)\n",
    "    knn_dist,knn_idx=knn.kneighbors(coords)\n",
    "    knn_idx=knn_idx[:,1:] #Removes the self hit\n",
    "    #print(knn_dist[9,:],knn_idx[9,:])\n",
    "\n",
    "    #Edge construction\n",
    "    src=np.repeat(np.arange(N),k)\n",
    "    dst=knn_idx.reshape(-1)\n",
    "    mask=dst>=0\n",
    "    src,dst=src[mask],dst[mask]\n",
    "    edge_index=torch.tensor(np.vstack([src,dst]),dtype=torch.long)\n",
    "\n",
    "    #Edge attributes\n",
    "    edge_attr = torch.tensor((E[src] * E[dst]).reshape(-1, 1),dtype=torch.float)\n",
    "\n",
    "    #Final creation\n",
    "    graph= Data(x=node_features,edge_index=edge_index,edge_attr=edge_attr)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba20d905-3d16-48fa-b34b-2df22443a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph=[create_graph(event,k=8) for event in events]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02fffa-b6c3-4b43-b6a4-8415859e4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating graphs for all events\n",
    "graph=[]\n",
    "for event,pid in all_events_noisy:\n",
    "    g=create_graph(event,k=8)\n",
    "    profile=layer_profile(event,global_max_layers=50)\n",
    "    if g is not None:\n",
    "        g.y=torch.tensor([pid],dtype=torch.long)\n",
    "        g.layer_profile=profile\n",
    "        graph.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1038170-5308-45d6-8d7b-255671e0b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328d802-f6e6-400e-b56d-541b55aafffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging-1\n",
    "#for g in graph[:20]:\n",
    "#    print(g.y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2e5ce-ae84-4832-97d0-a53dcf096777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging-2\n",
    "#g = graph[3]\n",
    "#print(g.y)\n",
    "#print(g.y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679be9ca-805b-49fc-9938-ec82528316a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test-1\n",
    "graph[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951178ef-2765-4294-966b-6857af51e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test-2\n",
    "graph[2].layer_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf67de-9d0b-43a2-bea5-bc1107a2be1d",
   "metadata": {},
   "source": [
    "## Splitting into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd3505-d8ff-4b69-b200-8ce0ffb7af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#First split: Train vs Temp(Val+Test)\n",
    "train_data, temp_data= train_test_split(graph, test_size=0.3, random_state=42)\n",
    "\n",
    "#Second split: Test vs Val\n",
    "val_data, test_data= train_test_split(temp_data, test_size=0.7, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3745bb-7414-41cb-b45b-0fcfb7e1deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph[:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb0bb6-f8eb-460e-a5c8-152984544e99",
   "metadata": {},
   "source": [
    "## Using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e2cbca-e32a-4fe4-a46f-2e4c2930da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "batch_size=64\n",
    "\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader=DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6429c387-d722-4492-9e78-040854c386ef",
   "metadata": {},
   "source": [
    "## Making the GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674ec77-d500-426c-93a0-b1a415d3f057",
   "metadata": {},
   "source": [
    "### Developing the Message Passing Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5c1cf-89a3-4e80-8f69-56eca36e169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the message passing network\n",
    "import torch\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        #Here, in_channels: Input node features\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin=Linear(in_channels,out_channels,bias=False)\n",
    "        self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "        \n",
    "    def forward(self,x,edge_index):\n",
    "        # x has the shape [No. of hits, in_channels]\n",
    "        #edge_index has shape [2, No. of edges]\n",
    "        #Step-1: Add self loops\n",
    "        edge_index,_=add_self_loops(edge_index,num_nodes=x.size(0))\n",
    "        #Step-2: Linearly transform node feature matrix\n",
    "        x=self.lin(x)\n",
    "        #Step-3: Compute Normalization\n",
    "        row,col=edge_index\n",
    "        deg=degree(col,x.size(0))\n",
    "        deg_inv_sqr=deg.pow(-0.5)\n",
    "        deg_inv_sqr[deg_inv_sqr==float('inf')]=0\n",
    "        norm=deg_inv_sqr[row]*deg_inv_sqr[col]\n",
    "        #Step-4-5: Propagating the message- Normalize the node features and then add\n",
    "        out=self.propagate(edge_index,x=x,norm=norm)\n",
    "        #Step 6: Apply the end bias vector\n",
    "        out=out+self.bias\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1,1)*x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a6aa4-bdd6-4847-8a9d-c3e9a96e30a2",
   "metadata": {},
   "source": [
    "### Stacking the GNN layers for 'Convolution'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eff9734-6404-421d-ae98-94e3de618164",
   "metadata": {},
   "source": [
    "#### Advanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78281b39-b65f-423e-afb7-18348f4e372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "#from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_add_pool,BatchNorm\n",
    "\n",
    "class GCN_Event_Classifier(nn.Module):\n",
    "    def __init__(self, input_dim,hidden_dim,output_dim):\n",
    "        super().__init__()\n",
    "        #The GCN Layers\n",
    "        ## First-layer\n",
    "        self.conv1=GCNConv(input_dim,hidden_dim)\n",
    "        self.bn1=BatchNorm(hidden_dim)\n",
    "        ## 6 repeated blocks\n",
    "        self.convs=nn.ModuleList()\n",
    "        self.bns=nn.ModuleList()\n",
    "        for i in range(6):\n",
    "            self.convs.append(GCNConv(hidden_dim,hidden_dim))\n",
    "            self.bns.append(BatchNorm(hidden_dim))\n",
    "        ##Final layer\n",
    "        self.final_conv=GCNConv(hidden_dim,hidden_dim)\n",
    "        #Regularization\n",
    "        self.dropout=nn.Dropout(p=0.1)\n",
    "        \n",
    "        #Output- MLP- mainly doing the classification task.\n",
    "        self.output=nn.Sequential(\n",
    "            nn.Linear(hidden_dim+50,hidden_dim),\n",
    "            #nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,hidden_dim),\n",
    "            #nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self,data):\n",
    "        #x,edge_index=data.x, data.edge_index\n",
    "        x,edge_index,batch=data.x,data.edge_index,data.batch\n",
    "        #print(data.x.shape)\n",
    "        \n",
    "        #-----------Graph Convolution--------------\n",
    "        #####First GCN Block#######\n",
    "        x=self.conv1(x,edge_index)\n",
    "        x=self.bn1(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.dropout(x)\n",
    "        #### Repeated convolutions ####\n",
    "        for conv,bn in zip(self.convs,self.bns):\n",
    "            x=conv(x,edge_index)\n",
    "            x=bn(x)\n",
    "            x=F.relu(x)\n",
    "            x=self.dropout(x)\n",
    "        #### Final convolution ####\n",
    "        x=self.final_conv(x,edge_index)\n",
    "        #Saving the node embeddings\n",
    "        node_embedding=x\n",
    "        #print(node_embedding.shape)\n",
    "        \n",
    "        #Graph-level event embedding\n",
    "        event_embedding=global_add_pool(x,batch) # shape: [batch_size,hidden_dim]\n",
    "        #print(event_embedding.shape)\n",
    "        \n",
    "        #Get layer profile\n",
    "        layer_profile=data.layer_profile\n",
    "        #print(layer_profile.shape)\n",
    "        #if layer_profile.dim()==1:\n",
    "        #    layer_profile=layer_profile.unsqueeze(0)\n",
    "        layer_profile=layer_profile.float()\n",
    "        #layer_profile.unsqueeze(0)\n",
    "        #if layer_profile.size(0)!=event_embedding.size(0):\n",
    "        #    layer_profile=layer_profile.expand(event_embedding.size(0),-1)\n",
    "            \n",
    "        \n",
    "        #layer_profile=data.layer_profile.float()\n",
    "        #Combined- Concatenate the features\n",
    "        combined=torch.cat([event_embedding,layer_profile],dim=1)\n",
    "        #print(combined.shape)\n",
    "        #Node-level-predictions\n",
    "        out=self.output(combined)\n",
    "        \n",
    "        return out,node_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a51e81-b3db-4161-9be8-9313e1995dc6",
   "metadata": {},
   "source": [
    "## Making the GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2dc9f-5ffc-4341-8b42-2396da33dae0",
   "metadata": {},
   "source": [
    "### Making the Message Passing Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a04ff0-ee90-4df3-99e7-b71bef156fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e9af2db-2d78-460d-a25e-cd748ff74beb",
   "metadata": {},
   "source": [
    "### Stacking the GAT layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b2d1a-6826-4b09-a604-849b346ab532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import global_add_pool,BatchNorm\n",
    "\n",
    "class GAT_Event_Classifier(nn.Module):\n",
    "    def __init__(self, input_dim,hidden_dim,output_dim,heads):\n",
    "        super().__init__()\n",
    "        self.heads=heads\n",
    "        #The GCN Layers\n",
    "        ## First-layer\n",
    "        #self.conv1=GCNConv(input_dim,hidden_dim)\n",
    "        self.conv1=GATConv(input_dim,hidden_dim, heads=heads,concat=False,dropout=0.1) \n",
    "        #concat=False means 'mean of two heads\n",
    "        self.bn1=BatchNorm(hidden_dim)\n",
    "        ## 6 repeated blocks\n",
    "        self.convs=nn.ModuleList()\n",
    "        self.bns=nn.ModuleList()\n",
    "        for i in range(6):\n",
    "            self.convs.append(GATConv(hidden_dim,hidden_dim,heads=heads,concat=False,dropout=0.1))\n",
    "            self.bns.append(BatchNorm(hidden_dim))\n",
    "        ##Final layer\n",
    "        self.final_conv=GATConv(hidden_dim,hidden_dim,heads=heads,concat=False,dropout=0.1)\n",
    "        #Regularization\n",
    "        self.dropout=nn.Dropout(p=0.1)\n",
    "        \n",
    "        #Output- MLP- mainly doing the classification task.\n",
    "        self.output=nn.Sequential(\n",
    "            nn.Linear(hidden_dim+50,hidden_dim),\n",
    "            #nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,hidden_dim),\n",
    "            #nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self,data):\n",
    "        #x,edge_index=data.x, data.edge_index\n",
    "        x,edge_index,batch=data.x,data.edge_index,data.batch\n",
    "        #print(data.x.shape)\n",
    "        \n",
    "        #-----------Graph Convolution--------------\n",
    "        #####First GCN Block#######\n",
    "        x=self.conv1(x,edge_index)\n",
    "        x=self.bn1(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.dropout(x)\n",
    "        #### Repeated convolutions ####\n",
    "        for conv,bn in zip(self.convs,self.bns):\n",
    "            x=conv(x,edge_index)\n",
    "            x=bn(x)\n",
    "            x=F.relu(x)\n",
    "            x=self.dropout(x)\n",
    "        #### Final convolution ####\n",
    "        x=self.final_conv(x,edge_index)\n",
    "        #Saving the node embeddings\n",
    "        node_embedding=x\n",
    "        #print(node_embedding.shape)\n",
    "        \n",
    "        #Graph-level event embedding\n",
    "        event_embedding=global_add_pool(x,batch) # shape: [batch_size,hidden_dim]\n",
    "        #print(event_embedding.shape)\n",
    "        \n",
    "        #Get layer profile\n",
    "        layer_profile=data.layer_profile\n",
    "        #print(layer_profile.shape)\n",
    "        #if layer_profile.dim()==1:\n",
    "        #    layer_profile=layer_profile.unsqueeze(0)\n",
    "        layer_profile=layer_profile.float()\n",
    "        #layer_profile.unsqueeze(0)\n",
    "        #if layer_profile.size(0)!=event_embedding.size(0):\n",
    "        #    layer_profile=layer_profile.expand(event_embedding.size(0),-1)\n",
    "            \n",
    "        \n",
    "        #layer_profile=data.layer_profile.float()\n",
    "        #Combined- Concatenate the features\n",
    "        combined=torch.cat([event_embedding,layer_profile],dim=1)\n",
    "        #print(combined.shape)\n",
    "        #Node-level-predictions\n",
    "        out=self.output(combined)\n",
    "        \n",
    "        return out,node_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09c575-b966-4895-8224-0afc8e77ef6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df573c8-65b4-48fb-b2d9-ad21a43b8e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdd241-4d6c-4403-9059-0b72d11ae749",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08d062-4d8e-4a68-a3c1-cf6caeda062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9e1d6-0f07-49fb-aeb8-2869c32c8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=GCN_Event_Classifier(input_dim=5,hidden_dim=64,output_dim=9).to(device)\n",
    "layer_dim=graph[0].layer_profile.shape[0]\n",
    "model=GAT_Event_Classifier(input_dim=5,hidden_dim=25,heads=2,output_dim=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49240b79-7eaa-45f5-b912-08a28c6d11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66811ba4-03a5-4c92-b9ee-955288472b48",
   "metadata": {},
   "source": [
    "### Developing the training, validation and testing loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55211511-6d13-4d58-b0b9-3ed6321f1f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "criterion=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc1f95-0256-4100-996d-520398f9017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss=0.0\n",
    "    for batch in train_loader:\n",
    "        batch=batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #Computing batchwise layer profiles\n",
    "        #profiles=layer_profile_batchwise(batch,global_max_layers=50)\n",
    "        out,_=model(batch)\n",
    "        loss=criterion(out,batch.y)\n",
    "        #Backpropagation\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        total_loss+=loss.item()\n",
    "        \n",
    "    return total_loss/len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2247520b-ef4b-420c-b7e9-452dbc0d064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation loop\n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss=0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch=batch.to(device)\n",
    "            out,_=model(batch)\n",
    "            loss=criterion(out,batch.y)\n",
    "            total_loss+=loss.item()\n",
    "    return total_loss/len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9841380-e44c-4e02-bc08-5153b8f86530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the model\n",
    "epochs=100\n",
    "#epochs=500\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "for epochs in range(1,epochs+1):\n",
    "    train_loss=train()\n",
    "    val_loss=validate()\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epochs}, Train Loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20654587-cfc5-4600-aeee-f6d73d57ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the model performance\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(1,len(train_losses)+1),train_losses,label=\"Training loss\",color=\"Blue\")\n",
    "plt.plot(range(1,len(val_losses)+1),val_losses,label=\"Validation loss\",color=\"Red\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8626dc2f-195a-4d9b-900a-a75e32a921cd",
   "metadata": {},
   "source": [
    "### Inferences(Performance) of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cefda6-0452-4031-9096-6f526717b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "model.eval()\n",
    "predictions=[]\n",
    "true_labels=[]\n",
    "probablities=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch=batch.to(device)\n",
    "        out,_=model(batch)\n",
    "        preds=torch.argmax(out,dim=1)  #Predictions\n",
    "        probs=torch.softmax(out,dim=1) #Probablities\n",
    "        \n",
    "        predictions.append(preds.cpu())\n",
    "        true_labels.append(batch.y.cpu())\n",
    "        probablities.append(probs.cpu())\n",
    "    \n",
    "predictions=torch.cat(predictions)\n",
    "true_labels=torch.cat(true_labels)\n",
    "probablities=torch.cat(probablities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49445a4f-e36a-46a4-aa21-95e9a56ac004",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbcb32-0119-4b3d-af40-18966fcdf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm=confusion_matrix(true_labels,predictions,normalize='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008f954-7ef6-4eb2-bc60-025bfa967ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = {v: k for k, v in particle_ids.items()}\n",
    "class_names=[pid[i] for i in range(len(pid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91f284-991b-4f5d-9521-c50a5cba31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt='.2%',\n",
    "            cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "\n",
    "plt.xlabel(\"Predicted Particle\")\n",
    "plt.ylabel(\"True Particle\")\n",
    "plt.title(\"Confusion Matrix - Particle Identification\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fbb3bf-d5ed-4606-aeb5-3c75a239f821",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101fe5e-cf6e-44cd-8550-8200ec3686c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "#Here, we need to convert the labels to one-hot levels for ROC only\n",
    "num_classes=3\n",
    "y_true_bin=label_binarize(true_labels.numpy(),classes=range(num_classes))\n",
    "y_score=probablities.numpy()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr, tpr,_=roc_curve(y_true_bin[:,i],y_score[:,i])\n",
    "    roc_auc=auc(fpr,tpr)\n",
    "    plt.plot(fpr,tpr,label=f'{class_names[i]}(AUC={roc_auc:.2f})')\n",
    "plt.grid()\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Multi-Class ROC Curves-GCN\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ccbd0-7109-4aec-b49f-d9f256e4e2fc",
   "metadata": {},
   "source": [
    "#### Signal and Background distribution per particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf10cf-0d06-4f9d-bc73-55a56eb06d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = {v: k for k, v in particle_ids.items()}\n",
    "class_names=[pid[i] for i in range(len(pid))]\n",
    "for i, name in enumerate(class_names):\n",
    "    #Signal\n",
    "    signal_mask = (true_labels == i)\n",
    "    signal_probs = probablities[signal_mask, i].cpu().numpy()\n",
    "    #Background\n",
    "    background_mask=(true_labels!=i)\n",
    "    background_probs=probablities[background_mask,i].cpu().numpy()\n",
    "    #Plotting\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.hist(signal_probs,bins=50,histtype='step',color='blue', density=True,linewidth=2,alpha=0.7,label='Signal')\n",
    "    plt.hist(background_probs,bins=50,histtype='step',color='red', density=True,linewidth=2,alpha=0.7,linestyle='--',label='Background')\n",
    "    plt.xlabel(f\"P({name})\")\n",
    "    plt.ylabel(\"Normalised Entries\")\n",
    "    plt.title(f\"Signal and Background Distribution for {name}\")\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318191aa-d147-4e95-9627-7112c0fa9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subplot view\n",
    "pid = {v: k for k, v in particle_ids.items()}\n",
    "class_names=[pid[i] for i in range(len(pid))]\n",
    "num_classes=len(class_names)\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 14,\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    \"axes.linewidth\": 1.5,\n",
    "})\n",
    "fig,axes=plt.subplots(1,num_classes,figsize=(5*num_classes,2*num_classes),sharey=True)\n",
    "\n",
    "for i,(ax,name) in enumerate(zip(axes,class_names)):\n",
    "    #Signal\n",
    "    signal_mask=(true_labels==i)\n",
    "    signal_probs=probablities[signal_mask,i].cpu().numpy()\n",
    "    #Background\n",
    "    background_mask=(true_labels!=i)\n",
    "    background_probs=probablities[background_mask,i].cpu().numpy()\n",
    "    #Plotting\n",
    "    #bins=np.linspace(0,1,50)\n",
    "    #plt.figure(figsize=(6,5))\n",
    "    ax.hist(signal_probs,bins=50,histtype='step',color='blue', density=True,linewidth=2,alpha=0.7,label='Signal')\n",
    "    ax.hist(background_probs,bins=50,histtype='step',color='red', density=True,linewidth=2,alpha=0.7,linestyle='--',label='Background')\n",
    "    ax.set_xlabel(f\"P({name})\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_yscale('log')\n",
    "    #ax.set_xlim(0,1)\n",
    "    #plt.title(f\"Probablity distribution of True {name}\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530437da-703b-4541-b7d1-51ef7b191a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421caf0-bbfb-436e-9a19-5ffb9d19b75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
